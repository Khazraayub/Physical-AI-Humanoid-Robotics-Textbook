---
title: Synthetic Data & Perception
description: Learn about synthetic data generation and perception in Isaac Sim.
keywords: [Isaac Sim, synthetic data, perception, robotics]
order: 2
---

# Synthetic Data & Perception

This chapter covers how to generate synthetic data and use it for training perception models in NVIDIA Isaac Sim.

One of the biggest challenges in developing AI-based robots is the need for large amounts of labeled data to train perception models. Collecting and labeling real-world data can be a time-consuming and expensive process. This is where synthetic data generation comes in. Synthetic data is data that is generated by a computer simulation, rather than being collected from the real world.

NVIDIA Isaac Sim provides a powerful set of tools for generating synthetic data for robotics. You can create realistic 3D environments, place objects in the scene, and then render images from different camera angles. Isaac Sim can also automatically generate labels for the data, such as semantic segmentation masks, bounding boxes, and depth images. This allows you to quickly generate large datasets for training and testing your perception algorithms.

The key advantage of using synthetic data is that you have complete control over the data generation process. You can easily create a wide variety of scenarios and edge cases that may be difficult or dangerous to capture in the real world. You can also randomize various parameters, such as lighting, textures, and object poses, to create a more diverse and robust dataset. This can lead to better performance and generalization of your perception models when they are deployed on a physical robot.

### Types of Synthetic Data

Isaac Sim can generate a wide range of synthetic data, including:
- **RGB Images**: Standard color images from a simulated camera.
- **Depth Images**: Images that contain the distance from the camera to each pixel in the scene.
- **Semantic Segmentation Masks**: Images where each pixel is labeled with the class of the object that it belongs to (e.g., car, person, building).
- **Instance Segmentation Masks**: Similar to semantic segmentation masks, but each instance of an object is given a unique label.
- **Bounding Boxes**: 2D or 3D boxes that enclose each object in the scene.
- **Lidar Scans**: Simulated data from a LiDAR sensor, which can be used for tasks such as localization and mapping.
- **Radar Scans**: Simulated data from a radar sensor, which can be used for tasks such as object detection and tracking.

By combining these different types of synthetic data, you can create a rich and diverse dataset for training and testing your perception algorithms. This can help to improve the performance and robustness of your AI-based robot.
